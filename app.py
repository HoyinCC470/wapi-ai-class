import streamlit as st
from openai import OpenAI
import os

# ================= é…ç½®åŒºåŸŸ =================
# å»ºè®®åœ¨ Sealos ç¯å¢ƒå˜é‡é‡Œè®¾ç½®ï¼Œè¿™é‡Œä½œä¸ºä¿åº•
API_BASE = os.getenv("API_BASE", "https://æ‚¨çš„OneAPIåŸŸå.zeabur.app/v1")
API_KEY = os.getenv("API_KEY", "sk-æ‚¨çš„OneAPIä»¤ç‰Œ")

# æ¨¡å‹åç§° (å¿…é¡»è¦å’Œ OneAPI é‡Œæ·»åŠ çš„ä¸€è‡´)
TEXT_MODEL = "qwen-turbo"
IMAGE_MODEL = "black-forest-labs/FLUX.1-schnell" # æˆ–è€… dall-e-3 (å¦‚æœæ‚¨åšäº†é‡å®šå‘)
# ===========================================

st.set_page_config(page_title="AI å½±ç‰‡åˆ›ä½œæµ", layout="wide")
st.title("ğŸ¬ AI å½±ç‰‡åˆ¶ä½œè¯¾ç¨‹å·¥ä½œå°")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(api_key=API_KEY, base_url=API_BASE)

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.info(f"å½“å‰æ¥å…¥ï¼šOneAPI \n\n æ¨¡å‹ï¼š{TEXT_MODEL} | {IMAGE_MODEL}")
    st.markdown("---")
    st.markdown("### ğŸ’¡ ä½¿ç”¨æŒ‡å—")
    st.markdown("1. å…ˆç”¨ **ç¼–å‰§** å†™æ•…äº‹")
    st.markdown("2. å¤åˆ¶ç”»é¢æè¿°åˆ° **åˆ†é•œ**")
    st.markdown("3. ç”Ÿæˆå›¾ç‰‡ä¿å­˜")

# åˆ›å»ºä¸‰ä¸ªæ ‡ç­¾é¡µ
tab1, tab2, tab3 = st.tabs(["ğŸ“ å‰§æœ¬åˆ›ä½œ", "ğŸ¨ åˆ†é•œç»˜åˆ¶", "ğŸ¥ è§†é¢‘ç”Ÿæˆ"])

# --- Tab 1: æ–‡æœ¬å¯¹è¯ ---
with tab1:
    st.subheader("å‰§æœ¬ä¸è„šæœ¬åˆ›ä½œ")
    
    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³æ‹ä»€ä¹ˆæ•…äº‹ï¼Ÿ"}]

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # è¾“å…¥æ¡†
    if prompt := st.chat_input("è¾“å…¥æ•…äº‹å¤§çº²..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            stream = client.chat.completions.create(
                model=TEXT_MODEL,
                messages=st.session_state.messages,
                stream=True
            )
            response = st.write_stream(stream)
        
        st.session_state.messages.append({"role": "assistant", "content": response})

# --- Tab 2: æ–‡ç”Ÿå›¾ ---
with tab2:
    st.subheader("åˆ†é•œç”»é¢ç”Ÿæˆ (Flux/Kolors)")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        img_prompt = st.text_area("ç”»é¢æè¿° (æç¤ºè¯)", height=150, placeholder="ä¾‹å¦‚ï¼šèµ›åšæœ‹å…‹é£æ ¼çš„è¡—é“ï¼Œéœ“è™¹ç¯ï¼Œé›¨å¤œï¼Œé«˜æ¸…...")
        generate_btn = st.button("ç”Ÿæˆç”»é¢", type="primary")
    
    with col2:
        if generate_btn and img_prompt:
            with st.spinner("æ­£åœ¨ç»˜åˆ¶åˆ†é•œï¼Œè¯·ç¨å€™..."):
                try:
                    # è°ƒç”¨ç”Ÿå›¾ API
                    response = client.images.generate(
                        model=IMAGE_MODEL,
                        prompt=img_prompt,
                        size="1024x1024",
                        n=1
                    )
                    image_url = response.data[0].url
                    st.image(image_url, caption="ç”Ÿæˆç»“æœ", use_column_width=True)
                    st.success("ç”ŸæˆæˆåŠŸï¼å³é”®å¯ä¿å­˜å›¾ç‰‡ã€‚")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

# --- Tab 3: è§†é¢‘ (é¢„ç•™) ---
with tab3:
    st.subheader("å›¾ç”Ÿè§†é¢‘ / æ–‡ç”Ÿè§†é¢‘")
    st.info("âš ï¸ è§†é¢‘ç”Ÿæˆæ¥å£éœ€è¦å•ç‹¬æ¥å…¥ (å¦‚ Kling/Runway)ï¼Œç›®å‰ OneAPI å¯¹è§†é¢‘æ”¯æŒå°šä¸å®Œå–„ã€‚å»ºè®®å­¦ç”Ÿä½¿ç”¨ç”Ÿæˆçš„å›¾ç‰‡ï¼Œå»å¯çµ/å³æ¢¦å®˜ç½‘ç”Ÿæˆè§†é¢‘ã€‚")