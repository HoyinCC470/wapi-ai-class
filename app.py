import streamlit as st
from openai import OpenAI
import os

# === 1. åŸºç¡€é…ç½® ===
# è¯·ç¡®ä¿è¿™é‡Œå¡«çš„æ˜¯ä½ çš„ OneAPI åœ°å€ (æœ«å°¾å¸¦ /v1) å’Œ ä»¤ç‰Œ
API_BASE = os.getenv("API_BASE", "https://api.your-oneapi-domain.com/v1") 
API_KEY = os.getenv("API_KEY", "sk-xxxxxxxxxxxxxxxxxxxxxxxx")

# === æ¨¡å‹æ˜ å°„é…ç½® ===
TEXT_MODELS_MAP = {
    "DeepSeek V3.2": "deepseek-ai/DeepSeek-V3.2-Exp",
    "Qwen3 14B": "Qwen/Qwen3-14B",
    "Gemini 2.5": "gemini-2.5-flash",
    "Qwen Coder 480B": "Qwen/Qwen3-coder-480b-a35b-instruct" 
}

IMAGE_MODELS_MAP = {
    "Kwai Kolors": "Kwai-Kolors/Kolors",
    "Qwen Image": "Qwen/Qwen-Image",
    # --- é€šä¹‰ä¸‡ç›¸ Turbo æ¨¡å‹ ---
    "Tongyi Turbo": "Tongyi-MAI/Z-Image-Turbo"
}

# === æ–°å¢ï¼šåˆ†è¾¨ç‡ä¸æ¯”ä¾‹æ˜ å°„é…ç½® ===
# è¿™é‡Œå®šä¹‰äº†ä¸åŒæ¯”ä¾‹ä¸‹ï¼ŒOneAPI/å¸¸ç”¨æ¨¡å‹é€šå¸¸æ”¯æŒçš„æ ‡å‡†åˆ†è¾¨ç‡
ASPECT_RATIOS = {
    "1:1 (æ–¹å½¢æ„å›¾)": ["1024x1024", "512x512", "2048x2048"],
    "3:4 (å°çº¢ä¹¦/æµ·æŠ¥)": ["768x1024", "1152x1536"],
    "4:3 (æ ‡å‡†å±å¹•)": ["1024x768", "1536x1152"],
    "9:16 (æ‰‹æœºç«–å±)": ["720x1280", "1024x1792"],
    "16:9 (ç”µå½±å®½å±)": ["1280x720", "1792x1024"]
}

# === 2. é¡µé¢è®¾ç½® ===
st.set_page_config(
    page_title="æœªæ¹ƒ WAPI Â· AI æ™ºèƒ½å·¥ä½œå°",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === 3. çŠ¶æ€ç®¡ç† ===
if 'active_workflow' not in st.session_state:
    st.session_state.active_workflow = 'text' 
if 'selected_text_model_index' not in st.session_state:
    st.session_state.selected_text_model_index = 0
if 'selected_image_model_index' not in st.session_state:
    st.session_state.selected_image_model_index = None

def on_text_model_change():
    st.session_state.active_workflow = 'text'
    st.session_state.selected_image_model_index = None 

def on_image_model_change():
    st.session_state.active_workflow = 'image'
    st.session_state.selected_text_model_index = None 

# === 4. CSS æ ·å¼ ===
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stAppDeployButton {display: none;}
    header {visibility: visible !important; background-color: transparent !important;}
    .main .block-container {padding-top: 2rem !important; padding-bottom: 2rem !important; max-width: 100% !important;}
    :root { --brand-blue: #0052D4; --brand-yellow: #FF9F43; }
    .brand-blue { color: var(--brand-blue) !important; }
    .brand-yellow { color: var(--brand-yellow) !important; }
    .brand-container { margin-bottom: 30px; text-align: center; }
    .brand-title { font-size: 32px !important; font-weight: 800 !important; letter-spacing: -0.5px; line-height: 1.3 !important; margin: 0 !important; color: var(--text-color) !important; }
    .brand-caption { font-size: 12px !important; color: var(--text-color) !important; opacity: 0.7; font-weight: 500; margin-top: 5px !important; }
    .sidebar-header { font-size: 18px !important; font-weight: 800 !important; color: var(--text-color) !important; opacity: 1.0 !important; margin-top: 30px !important; margin-bottom: 10px !important; padding-left: 8px !important; border-left: 4px solid var(--brand-yellow); line-height: 1.2; }
    .stRadio { margin-top: 0px !important; } .stRadio div[role="radiogroup"] { gap: 0px !important; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarUser"]), div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) { flex-direction: row-reverse !important; text-align: right; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarUser"]) div[data-testid="stChatMessageContentContainer"], div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) div[data-testid="stChatMessageContentContainer"] { background-color: var(--secondary-background-color) !important; color: var(--text-color) !important; border: 1px solid var(--brand-blue) !important; border-radius: 12px 2px 12px 12px !important; padding: 10px 16px !important; margin-right: 10px !important; margin-left: 50px !important; box-shadow: 0 2px 8px rgba(0, 82, 212, 0.15); display: inline-block; text-align: left; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarUser"]) p, div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) p { color: var(--text-color) !important; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarUser"]) div[data-testid="stChatMessageAvatarUser"], div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) div[data-testid="chatAvatarIcon-user"] { background-color: transparent !important; border: 1px solid var(--brand-blue) !important; color: var(--brand-blue) !important; }
    div[data-testid="stChatMessageAvatarUser"] svg, div[data-testid="chatAvatarIcon-user"] svg { fill: var(--brand-blue) !important; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarAssistant"]), div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-assistant"]) { flex-direction: row !important; }
    div[data-testid="stChatMessage"]:has(div[data-testid="stChatMessageAvatarAssistant"]) div[data-testid="stChatMessageContentContainer"], div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-assistant"]) div[data-testid="stChatMessageContentContainer"] { background-color: var(--secondary-background-color) !important; border: 1px solid rgba(128, 128, 128, 0.2) !important; color: var(--text-color) !important; border-radius: 2px 12px 12px 12px !important; padding: 10px 16px !important; margin-left: 10px !important; margin-right: 50px !important; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"], div.stButton > button { background-color: var(--secondary-background-color) !important; color: var(--text-color) !important; border: 1px solid rgba(128, 128, 128, 0.2) !important; }
</style>
""", unsafe_allow_html=True)

# === 5. å®¢æˆ·ç«¯åˆå§‹åŒ– ===
if not API_KEY or not API_BASE:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ°é…ç½®ï¼è¯·è®¾ç½® API_BASE å’Œ API_KEY")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=API_BASE)

# === 6. æµå¼å¤„ç† ===
def stream_wrapper(response_stream):
    for chunk in response_stream:
        if chunk.choices and chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

# === 7. ä¾§è¾¹æ  ===
with st.sidebar:
    st.markdown("""
        <div class="brand-container">
            <div class="brand-title"><span class="brand-yellow">æœªæ¹ƒ WAPI</span><br><span class="brand-blue">AIGC å·¥ä½œå°</span></div>
            <div class="brand-caption">Ver 1.1 Slim | Powered by WAPI Team</div>
        </div>
    """, unsafe_allow_html=True)
    st.markdown('<div class="sidebar-header">WAPI å¤§è¯­è¨€æ¨¡å‹ä¸­å¿ƒ</div>', unsafe_allow_html=True)
    text_model_selection = st.radio("é€‰æ‹©æ¨¡å‹", list(TEXT_MODELS_MAP.keys()), index=st.session_state.selected_text_model_index if st.session_state.active_workflow == 'text' else None, key="text_radio", on_change=on_text_model_change, label_visibility="collapsed")
    st.markdown('<div class="sidebar-header">WAPI è§†è§‰æ¨¡å‹ä¸­å¿ƒ</div>', unsafe_allow_html=True)
    image_model_selection = st.radio("é€‰æ‹©æ¨¡å‹", list(IMAGE_MODELS_MAP.keys()), index=st.session_state.selected_image_model_index if st.session_state.active_workflow == 'image' else None, key="image_radio", on_change=on_image_model_change, label_visibility="collapsed")
    st.write(""); st.write("")
    if st.button("ğŸ—‘ï¸ é‡ç½®å½“å‰ä¼šè¯"):
        if "messages" in st.session_state: del st.session_state["messages"]
        st.rerun()

# === 8. ä¸šåŠ¡é€»è¾‘ ===

# --- A. æ–‡æœ¬å·¥ä½œæµ ---
if st.session_state.active_workflow == 'text':
    current_model_id = TEXT_MODELS_MAP.get(text_model_selection, list(TEXT_MODELS_MAP.values())[0])
    st.subheader(f"ğŸ¤– æ™ºèƒ½å¯¹è¯ - {text_model_selection}")
    st.caption(f"Engine: {current_model_id}")
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "system", "content": "ä½ æ˜¯æœªæ¹ƒWAPIçš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ä»¥ä¸“ä¸šã€ç®€æ´ä¸”å¯Œæœ‰åŠ©ç›Šçš„è¯­æ°”è¿›è¡Œå›ç­”ã€‚"}, {"role": "assistant", "content": f"ä½ å¥½ï¼æˆ‘æ˜¯æœªæ¹ƒWAPIçš„**{text_model_selection}**æ™ºèƒ½ä½“ã€‚æœ‰ä»€ä¹ˆå·¥ä½œæˆ–åˆ›æ„æˆ‘å¯ä»¥å¸®ä½ å¤„ç†ï¼Ÿ"}]
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"]): st.write(msg["content"])
    if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜ã€æŒ‡ä»¤æˆ–åˆ›ä½œéœ€æ±‚..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.write(prompt)
        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(model=current_model_id, messages=st.session_state.messages, stream=True)
                response = st.write_stream(stream_wrapper(stream))
                if response: st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e: st.error(f"è¯·æ±‚å¤±è´¥: {e}")

# --- B. å›¾åƒå·¥ä½œæµ (æ ¸å¿ƒä¿®å¤åŒºåŸŸ + æ–°å¢æ¯”ä¾‹/åˆ†è¾¨ç‡é€‰æ‹©) ---
elif st.session_state.active_workflow == 'image':
    current_model_id = IMAGE_MODELS_MAP.get(image_model_selection, list(IMAGE_MODELS_MAP.values())[0])
    st.subheader(f"ğŸ¨ è§†è§‰ç”Ÿæˆ - {image_model_selection}")
    st.caption("æœªæ¹ƒWAPI å›¾åƒç”Ÿæˆå¼•æ“æ”¯æŒ")
    col1, col2 = st.columns([1, 1.5], gap="medium")
    with col1:
        st.markdown("##### ğŸ› ï¸ ç”Ÿæˆå‚æ•°")
        
        # === æ–°å¢åŠŸèƒ½ï¼šæ¯”ä¾‹ä¸åˆ†è¾¨ç‡é€‰æ‹© (ä¸¤åˆ—å¸ƒå±€) ===
        ratio_col, res_col = st.columns(2)
        
        with ratio_col:
            # é»˜è®¤é€‰ä¸­ç¬¬ä¸€ä¸ª (1:1)
            selected_ratio_key = st.selectbox("ğŸ“ å›¾ç‰‡æ¯”ä¾‹", list(ASPECT_RATIOS.keys()), index=0)
            
        with res_col:
            # æ ¹æ®é€‰ä¸­çš„æ¯”ä¾‹ï¼ŒåŠ¨æ€è·å–å¯ç”¨çš„åˆ†è¾¨ç‡åˆ—è¡¨
            available_resolutions = ASPECT_RATIOS[selected_ratio_key]
            selected_resolution = st.selectbox("ğŸ“ åˆ†è¾¨ç‡", available_resolutions)

        style_preset = st.selectbox("ğŸ­ é£æ ¼æ»¤é•œ", ["âœ¨ åŸå›¾ (æ— é£æ ¼)", "ğŸï¸ ç”µå½±æ„Ÿ (Cinematic)", "ğŸŒƒ èµ›åšæœ‹å…‹ (Cyberpunk)", "ğŸ–Œï¸ æ°´å¢¨å›½é£ (Ink)", "ğŸ§¸ 3Dçš®å…‹æ–¯ (3D)"])
        img_prompt = st.text_area("âœï¸ åˆ›æ„æè¿°", height=200, placeholder="æè¿°ç”»é¢ä¸»ä½“ã€åœºæ™¯ç»†èŠ‚ã€å…‰å½±æ°›å›´æˆ–é…è‰²è¦æ±‚...")
        
        final_prompt = img_prompt
        if style_preset != "âœ¨ åŸå›¾ (æ— é£æ ¼)":
            style_suffix = {"ğŸï¸ ç”µå½±æ„Ÿ (Cinematic)": ", cinematic lighting, 8k, realistic, shallow depth of field, movie still", "ğŸŒƒ èµ›åšæœ‹å…‹ (Cyberpunk)": ", cyberpunk, neon lights, futuristic city, high contrast", "ğŸ–Œï¸ æ°´å¢¨å›½é£ (Ink)": ", traditional chinese ink painting, black and white", "ğŸ§¸ 3Dçš®å…‹æ–¯ (3D)": ", pixar style, 3d render, cute, soft lighting"}
            if img_prompt: final_prompt += style_suffix.get(style_preset, "")
            
        generate_btn = st.button("ğŸ¨ ç«‹å³ç”Ÿæˆ", type="primary", use_container_width=True)

    with col2:
        st.markdown("##### ğŸ–¼ï¸ ç»“æœé¢„è§ˆ")
        if generate_btn:
            if not img_prompt: st.warning("è¯·å…ˆè¾“å…¥åˆ›æ„æè¿°ï¼")
            else:
                with st.spinner(f"æ­£åœ¨è¯·æ±‚ {image_model_selection} ({selected_resolution}) è¿›è¡Œç»˜åˆ¶..."):
                    try:
                        # 1. å‘èµ·è¯·æ±‚ (ä½¿ç”¨åŠ¨æ€åˆ†è¾¨ç‡)
                        res = client.images.generate(
                            model=current_model_id,
                            prompt=final_prompt,
                            size=selected_resolution  # <--- ä½¿ç”¨ç”¨æˆ·é€‰ä¸­çš„åˆ†è¾¨ç‡
                        )
                        
                        image_url = None
                        
                        # 2. å°è¯•ä»¥æ ‡å‡† OpenAI æ–¹å¼è§£æ
                        if res and hasattr(res, 'data') and res.data:
                            image_url = res.data[0].url

                        # 3. é’ˆå¯¹ z-image-turbo çš„å…¼å®¹æ€§è§£æ
                        elif hasattr(res, 'model_dump'):
                            res_dict = res.model_dump()
                            if res_dict.get("images") and isinstance(res_dict["images"], list) and len(res_dict["images"]) > 0:
                                 image_url = res_dict["images"][0].get("url")

                        # 4. æ ¹æ®è§£æç»“æœæ˜¾ç¤º
                        if image_url:
                            st.image(image_url, use_container_width=True, caption=f"ç”Ÿæˆç»“æœ ({selected_resolution})")
                            st.success("ç”Ÿæˆå®Œæ¯•ï¼")
                            st.warning("âš ï¸ å›¾ç‰‡é“¾æ¥å…·æœ‰æ—¶æ•ˆæ€§ï¼Œè¯·å³é”®ä¿å­˜ã€‚")
                        else:
                            st.error(f"ç”Ÿæˆå¤±è´¥ï¼šAPI å“åº”æ ¼å¼å¼‚å¸¸ï¼Œæœªèƒ½è§£æå‡ºå›¾ç‰‡åœ°å€ã€‚")
                            try: st.json(res.model_dump())
                            except: st.write(res)
                                
                    except Exception as e:
                        st.error(f"è¯·æ±‚å‘ç”Ÿå¼‚å¸¸: {e}")
        else:
            st.info("ğŸ‘ˆ é€‰æ‹©æ¯”ä¾‹ï¼Œè¾“å…¥æè¿°ï¼Œç‚¹å‡»ç”ŸæˆæŒ‰é’®å¼€å§‹åˆ›ä½œã€‚")
