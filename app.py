import streamlit as st
from openai import OpenAI
import os

# === é…ç½®è¯»å– (ä»ç¯å¢ƒå˜é‡) ===
# å¦‚æœæœ¬åœ°è¿è¡Œæ²¡æœ‰ç¯å¢ƒå˜é‡ï¼Œä¼šä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼Œç•Œé¢ä¼šæç¤ºé…ç½®
API_BASE = os.getenv("API_BASE", "")
API_KEY = os.getenv("API_KEY", "")

# === ç•Œé¢è®¾ç½® ===
st.set_page_config(page_title="AI åˆ›ä½œå·¥ä½œå°", page_icon="ğŸ¬", layout="wide")

# è‡ªå®šä¹‰ CSS è®©ç•Œé¢æ›´å¹²å‡€
st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .main-header { font-size: 2rem; font-weight: 700; margin-bottom: 1rem; color: #333; }
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="main-header">ğŸ¬ å›¢é˜Ÿ AI å½±ç‰‡åˆ›ä½œæµ</div>', unsafe_allow_html=True)

# === æ£€æŸ¥é…ç½® ===
if not API_KEY or not API_BASE:
    st.warning("âš ï¸ å°šæœªæ£€æµ‹åˆ° API é…ç½®ã€‚è¯·åœ¨ Zeabur ç¯å¢ƒå˜é‡ä¸­è®¾ç½® API_KEY å’Œ API_BASEã€‚")
    st.stop()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
try:
    client = OpenAI(api_key=API_KEY, base_url=API_BASE)
except Exception as e:
    st.error(f"è¿æ¥å¤±è´¥: {e}")
    st.stop()

# === ä¾§è¾¹æ  ===
with st.sidebar:
    st.header("æµç¨‹é€‰æ‹©")
    mode = st.radio("è¯·é€‰æ‹©å·¥åº:", ["ğŸ“ å‰§æœ¬/è„šæœ¬åˆ›ä½œ", "ğŸ¨ åˆ†é•œç”»é¢ç”Ÿæˆ"])
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼š\n1. å‰§æœ¬ä½¿ç”¨ Qwen-Turbo\n2. ç”»é¢ä½¿ç”¨ Flux.1")

# === é€»è¾‘å¤„ç† ===

if mode == "ğŸ“ å‰§æœ¬/è„šæœ¬åˆ›ä½œ":
    st.subheader("å‰§æœ¬åˆ›ä½œåŠ©æ‰‹")
    
    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "æˆ‘æ˜¯ç¼–å‰§åŠ©æ‰‹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³å†™ä»€ä¹ˆæ•…äº‹ï¼Ÿ"}]

    # æ˜¾ç¤ºå†å²è®°å½•
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # å¤„ç†è¾“å…¥
    if prompt := st.chat_input("è¾“å…¥æ•…äº‹å¤§çº²..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            try:
                # å¼ºåˆ¶ä½¿ç”¨åƒé—®
                stream = client.chat.completions.create(
                    model="gpt-3.5-turbo", 
                    messages=st.session_state.messages, 
                    stream=True
                )
                response = st.write_stream(stream)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"ç”Ÿæˆå‡ºé”™: {e}")

elif mode == "ğŸ¨ åˆ†é•œç”»é¢ç”Ÿæˆ":
    st.subheader("åˆ†é•œç»˜åˆ¶ (Flux)")
    
    col1, col2 = st.columns([1, 1.5])
    
    with col1:
        img_prompt = st.text_area("ç”»é¢æè¿°", height=150, placeholder="ä¾‹å¦‚ï¼šä¸­å›½å¤ä»£åº­é™¢ï¼Œæ¡ƒèŠ±ç››å¼€ï¼Œä¸€ä½å°‘å¥³åœ¨å¼¹ç´ï¼Œç”µå½±è´¨æ„Ÿï¼Œ8kåˆ†è¾¨ç‡...")
        generate_btn = st.button("å¼€å§‹ç”Ÿæˆ", type="primary")
    
    with col2:
        if generate_btn:
            if not img_prompt:
                st.warning("è¯·è¾“å…¥æè¿°ï¼")
            else:
                with st.spinner("AI æ­£åœ¨ç»˜å›¾ï¼Œè¯·ç¨å€™ (çº¦3-5ç§’)..."):
                    try:
                        # å¼ºåˆ¶ä½¿ç”¨ Flux (è¯·ç¡®ä¿æ‚¨ OneAPI é‡Œæœ‰è¿™ä¸ªåå­—ï¼Œæˆ–è€…åšäº†é‡å®šå‘)
                        # å¦‚æœæ‚¨åšè¿‡é‡å®šå‘ dall-e-3 -> fluxï¼Œè¿™é‡Œå¯ä»¥æ”¹æˆ "dall-e-3"
                        res = client.images.generate(
                            model="dall-e-3", 
                            prompt=img_prompt, 
                            size="1024x1024"
                        )
                        image_url = res.data[0].url
                        st.image(image_url, caption="ç”Ÿæˆé¢„è§ˆ")
                        st.success("ç”ŸæˆæˆåŠŸï¼è¯·å³é”®ä¿å­˜å›¾ç‰‡ã€‚")
                    except Exception as e:
                        st.error(f"ç»˜å›¾å¤±è´¥: {e}\n\nè¯·æ£€æŸ¥ OneAPI æ—¥å¿—æˆ–ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ã€‚")
